# Deep Learning Fundamentals

Welcome to the Deep Learning Fundamentals repository! 

This repository is designed to help you understand and master the fundamentals of deep learning through a series of simple examples and scripts. 

For now, the content is organized based on the MIT course ["Introduction to Deep Learning"](http://introtodeeplearning.com/) and will be covering each lecture to provide a comprehensive learning experience.

## Course Structure

### Lecture 1: Introduction to Deep Learning
Example script and explanations to introduce you to the core concepts of deep learning.
- L1.ipynb
- lecture1.md

### Lecture 2: Deep Sequence Modeling
Explore deep learning techniques for sequence modeling, with practical examples.
- L2-recurrence.ipynb
- L2-transformers.ipynb

### Lecture 3: Deep Computer Vision
Dive into the world of deep learning for computer vision tasks.
- under development ...
  
### Lecture 4: Deep Generative Modeling
Learn about generative models and their applications in deep learning.
- under development ...
  
### Lecture 5: Uncertainty and Bias
Understand handling uncertainty and bias in deep learning models.
- under development ...
  
### Lecture 6: Deep Reinforcement Learning
Explore reinforcement learning techniques in the context of deep learning.
- under development ...
  
### Lecture 7: Limitations and New Frontiers
Discuss the limitations and explore new frontiers of deep learning.
- under development ...
  
### Lecture 8: Text-to-Image Generation
Delve into the exciting area of text-to-image generation.
- under development ...
  
### Lecture 9: The Modern Era of Statistics
- Learn about the modern aspects of statistics in the context of deep learning.
- under development ...
  
### Lecture 10: Robot Learning
- Explore how deep learning can be applied to robot learning.
- under development ...
  
## Getting Started

Each lecture folder contains example scripts and explanations to help you grasp the fundamental concepts of deep learning. Start by navigating to the specific lecture folder you're interested in and explore the provided resources.

Feel free to contribute your own scripts, insights, or enhancements to the examples. Let's embark on this journey to master the foundations of deep learning together!

Happy learning!

## References
Professor Tom Yeh recently developed 14  exercises that dive deep into the core of Generative AI, showing us that even the most advanced concepts can be understood from the ground up.

These exercises cover a wide range of topics, from the basics of vector databases to the complexities of generative adversarial networks (GANs) and transformers.

[1] Vector Database
https://lnkd.in/gTanDTMj

[2] Self Attention
https://lnkd.in/gDW8Um4W

[3] Transformer
https://lnkd.in/g39jcD7j

[4] GAN
https://lnkd.in/gyKzNGDy

[5] LLM Sampling
https://lnkd.in/gwe69_84

[6] Backpropagation
https://lnkd.in/gsiU2uc2

[7] Autoencoder
https://lnkd.in/g2rM9iV2

[8] Dropout
https://lnkd.in/g4KHF-Hd

[9] Batch Normalization
https://lnkd.in/gVjknYkU

[10] Mixture of Experts (MOEs)
https://lnkd.in/gPFdQdsW

[11] Recurrent Neural Network (RNN)
https://lnkd.in/gDANw4iH

[12] Mamba
https://lnkd.in/gGcS2sMa

[13] MLP in Pytorch
https://lnkd.in/gnjif8mX

[14] Matrix Multiplication
https://lnkd.in/gXKnQQF3
